{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.8631135] [[ -2.74146024e-02  -2.25297686e-01   1.21840881e-01   2.29362960e+00\n",
      "    2.70425727e-01   2.32851135e-01   9.28595398e-01   2.95200203e-01\n",
      "    1.62205924e-01   6.78259065e-02  -8.32603793e-02  -1.60373348e-01\n",
      "   -4.72247998e-02   1.07676963e-02   1.87903772e-01   8.19771791e-01\n",
      "    5.09529031e-01   3.98710853e-02   2.67729669e-01   3.47047290e-01\n",
      "    2.60498935e-01   3.64605723e-01   7.25019849e-01   1.96728229e-01\n",
      "   -3.15395711e+00  -4.03133853e-01  -1.25451036e+01  -6.16576365e-02\n",
      "   -1.56114580e+00  -5.51430802e-02  -3.00823299e-02   4.07263819e-01\n",
      "   -3.68156523e-01  -1.43611920e+00  -5.87182204e-01   4.44294622e-01\n",
      "    4.23159806e-02  -1.56897100e-01  -4.55330675e-01  -1.02250213e-01\n",
      "   -3.54273318e+00  -1.72944427e+00  -4.37529503e-01  -1.05999940e+00\n",
      "   -9.18599253e-01  -1.75490289e+00  -1.67475810e-01  -9.56875762e-01\n",
      "   -3.65653449e-01  -1.36535596e-01  -6.58692636e-02   2.06714075e-01\n",
      "    1.70694415e+00   1.21460288e+00  -3.35270344e-01   1.56141577e+00\n",
      "    3.68775509e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.89176909] [[-0.52572553 -0.25900436 -0.12451683  0.98386942  1.26209231  0.99279912\n",
      "   3.11891928  1.49962631  0.3233415   0.40920008 -0.60871995 -0.47831683\n",
      "  -0.86012541  0.41910489  0.76648431  1.58742579  1.54468563 -0.06147607\n",
      "   0.41004116  0.77873374  0.51241062  0.46376391  2.14181879  1.48323557\n",
      "  -3.69017815 -0.45895708 -9.9120433   0.18764588 -2.17427247  0.03854718\n",
      "  -0.03662297 -0.44155071 -1.0227786  -0.90003147 -1.78011304  1.64313419\n",
      "  -0.78800605 -0.48843914 -1.35171241 -0.42190531 -3.30779011 -3.4661574\n",
      "  -3.15376804 -2.88771875 -1.38810671 -3.20909217 -1.78639343 -4.1900911\n",
      "  -2.30528289 -0.91821183 -1.04821686  2.08942489  5.76965347  1.09688504\n",
      "   0.83111749  0.08060721  0.53239341]]\n",
      "Accuracy on set aside test set for  logt  =  0.94140625\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-1.77210462] [[-0.27015186 -0.13652527 -0.4410512   0.19593     1.09940155  0.28382542\n",
      "   2.39370642  0.89848236  0.26534633  0.43563225 -0.39727127 -0.42883142\n",
      "  -1.07464489  0.32304366  0.66669664  1.58604194  1.10346877 -0.17358507\n",
      "   0.24916045  0.76717814  0.78417461  1.42475185  1.0388407   1.61862531\n",
      "  -2.93736791 -0.23317791 -5.85002072  1.26265951 -0.83078991 -0.06707994\n",
      "  -1.65513785 -1.71955843 -0.92718034  0.44743645 -0.73941269  0.51820123\n",
      "  -1.06392633  1.07670397 -0.98242874 -0.32995979 -2.96962345 -2.53986104\n",
      "  -1.21091384 -2.16549066 -0.85214473 -2.56734117  0.03485509 -2.02740292\n",
      "  -0.37388168  0.22126837 -0.21524232  1.27340335  1.59564598 -0.03238821\n",
      "  -0.04454982 -0.04454982 -0.04454982]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-13.94712155] [[ -5.55835492e-02  -1.99315012e-01   1.09922862e-01   2.77552089e+00\n",
      "    2.67908765e-01   2.66108939e-01   8.93256416e-01   2.97984141e-01\n",
      "    2.53355188e-01   6.79565884e-02  -6.81742949e-02  -1.52376766e-01\n",
      "   -3.64601254e-02   1.89866667e-02   1.60854146e-01   7.96509153e-01\n",
      "    5.52526882e-01   3.45327785e-02   2.69317206e-01   3.38657609e-01\n",
      "    2.50567916e-01   3.25444142e-01   6.96436821e-01   1.72447146e-01\n",
      "   -3.23553183e+00  -3.10215535e-01  -5.28113546e+01  -6.16184322e-02\n",
      "   -1.47072427e+00  -1.46224381e-02   1.96647837e-01   4.89435101e-01\n",
      "   -3.24777824e-01  -3.76788254e-01  -7.61400177e-01   4.29900737e-01\n",
      "    6.12716976e-02  -1.55713777e-01  -4.54618884e-01  -4.32802206e-02\n",
      "   -5.88225893e+00  -1.89298860e+00  -5.42450193e-01  -1.01158627e+00\n",
      "   -9.19331308e-01  -1.77149478e+00  -1.72404039e-01  -1.23067807e+00\n",
      "   -3.47263140e-01  -1.38196678e-01  -5.44705121e-02   1.97341022e-01\n",
      "    1.71642421e+00   1.08031284e+00   3.75041727e-01   2.64830964e+00\n",
      "    3.18476106e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.923828125\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-5.01350823] [[ -0.54523289  -0.18215539  -0.12538482   0.94901309   1.27001681\n",
      "    1.1100931    3.11646617   1.47934715   0.48091267   0.50028867\n",
      "   -0.60597138  -0.46550717  -0.90922987   0.47814479   0.60488662\n",
      "    1.59005389   1.71748957  -0.09064253   0.41437241   0.85143805\n",
      "    0.51320524   0.47103454   2.22376043   1.40712239  -3.87789306\n",
      "   -0.30221987 -18.38364377   0.19967014  -2.50365998   0.           0.45274095\n",
      "    0.          -0.90859362   0.          -2.00023031   1.69343017\n",
      "   -0.65260767  -0.42855885  -1.40123996  -0.11067013  -9.39142827\n",
      "   -4.03364862  -3.93059123  -3.2098934   -1.49437799  -3.2838641\n",
      "   -2.39894293  -5.56926875  -2.44287923  -1.00570915  -0.76756731\n",
      "    2.09985885   6.62755258   1.12477559   0.79206019   0.06613047\n",
      "    0.5802435 ]]\n",
      "Accuracy on set aside test set for  logt  =  0.938802083333\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-1.09237968] [[-0.27354451 -0.12123314 -0.43822525  0.13384936  1.1040378   0.29942416\n",
      "   2.41989081  0.9046668   0.26684061  0.44627896 -0.41123427 -0.42706503\n",
      "  -1.09388281  0.31955185  0.66178516  1.5949121   1.13545755 -0.18143115\n",
      "   0.2425887   0.8024329   0.78792438  1.41373677  1.03791167  1.65720847\n",
      "  -3.01011937 -0.19718238 -6.21827927  1.30728271 -0.83117155 -0.04021118\n",
      "  -1.74088878 -1.90100809 -0.94423644  0.20469366 -0.7258322   0.52629155\n",
      "  -1.05126978  1.10801062 -0.99581113 -0.30678024 -4.06573848 -2.61228455\n",
      "  -1.25477862 -2.2190062  -0.86070376 -2.5872201   0.         -2.10679159\n",
      "  -0.38119657  0.21938801 -0.20742505  1.28178968  1.61366112 -0.01990973\n",
      "  -0.39098709 -0.32916618 -0.09773061]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
